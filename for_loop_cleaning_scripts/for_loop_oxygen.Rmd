---
title: "oxygen_clean_test"
author: "Anson Ekau"
date: "2024-05-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) #A toolbox full of more toolboxes
library(here) #Sets working directory, type the following in console or in a code chunk. 'here::set_here()' 
library(janitor) #Used to clean names
library(plotly) #Used to make ggplots interactive
```

#Set up
The "Set Up" sections sets the working directory using the here() function. It also defines the path to the raw data folder and the specific variable folder. Inside the variable folders are the raw data files. 
```{r echo=FALSE, message=FALSE, warning=FALSE}

# Set the working directory to the project root folder
here::set_here()

# Define the path to the raw data folder
raw_data_folder <- here("raw_data", "raw_oxygen")

# Get the list of files in the raw_pH folder
file_list <- list.files(path = raw_data_folder, full.names = TRUE)

```


#Define Read and Clean Function
The following chunk creates a function using loops to read in the raw data files. The files come in .txt and .csv. This is important to note because reading in these files uses different functions and specific arguments need to be set to read them in correctly. 
```{r}
# Define a function to read and clean the column names
read_and_clean_data <- function(file_path) {
  # Check if file is .csv or .txt
  file_ext <- tools::file_ext(file_path)
  
  if (file_ext == "csv") {
  data <- read_csv(file_path, skip = 1)
} else if (file_ext == "txt") {
  # Read the first line to check if it starts with "Serial"
  first_line <- readLines(file_path, n = 1)

  if (startsWith(first_line, "Serial")) {
    data <- read_tsv(file_path, skip = 1)
  } else {
    data <- read_tsv(file_path)
  }
} else {
  stop("Unsupported file format")
}



  # Clean column names using janitor's clean_names()
  data <- data %>% clean_names()
  
  data <- data %>% select(-matches("temp", ignore.case = TRUE))

  return(data)
}
```


#Define Read and Clean Function
The following chunk creates a function using loops to read in the raw data files. The files come in .txt and .csv. This is important to note because reading in these files uses different functions and specific arguments need to be set to read them in correctly. 

When reading in a text file there will most likely be separate date and time column. CSV files will have a combined date time column. Its important to check if there are multiple formats for the date time columns. 
```{r message=FALSE, warning=FALSE}

library(dplyr)
library(lubridate)

for (i in seq_along(file_list)) {
  data <- read_and_clean_data(file_list[i])

  # Add site location
  if (grepl("Kalauhaihai", file_list[i], ignore.case = TRUE)) {
    data$site <- "Kalauhaihai"
  } else if (grepl("Kanewai", file_list[i], ignore.case = TRUE)) {
    data$site <- "Kanewai"
  }

  # Site-specific tag
  # for (site_name in site_names) {
  #   if (grepl(site_name, file_list[i], ignore.case = TRUE)) {
  #     data$site_specific <- site_name
  #     break
  #   }
  # }

  # Standardize column names
  date_columns <- grep("date", names(data), ignore.case = TRUE)
  if (length(date_columns) > 0) {
    names(data)[date_columns] <- "date_time_hst"
  }

  oxygen_columns <- grep("do", names(data), ignore.case = TRUE)
  if (length(oxygen_columns) > 0) {
    names(data)[oxygen_columns] <- "oxygen"
  }

  # ---- Robust datetime parse (AM/PM or 24h) ----
  datetime_str <- NULL
  if ("date_time_hst" %in% names(data) && "time" %in% names(data)) {
    datetime_str <- paste(as.character(data$date_time_hst), as.character(data$time))
  } else if ("date_time_hst" %in% names(data)) {
    datetime_str <- as.character(data$date_time_hst)
  }

  if (!is.null(datetime_str)) {
    tz_hst <- "Pacific/Honolulu"

    am_pm_present <- any(grepl("\\b(AM|PM)\\b", datetime_str, ignore.case = TRUE), na.rm = TRUE)

    orders_am_pm <- c("mdy HMS p","dmy HMS p","ymd HMS p","mdy HM p","dmy HM p","ymd HM p")
    orders_24h   <- c("mdy HMS","dmy HMS","ymd HMS","mdy HM","dmy HM","ymd HM")
    orders <- if (am_pm_present) orders_am_pm else orders_24h

    dt <- parse_date_time(datetime_str, orders = orders, tz = tz_hst, quiet = TRUE)

    if (sum(is.na(dt)) > 0.5 * length(dt)) {
      backup_orders <- if (am_pm_present) orders_24h else orders_am_pm
      dt2 <- parse_date_time(datetime_str, orders = backup_orders, tz = tz_hst, quiet = TRUE)
      dt[is.na(dt)] <- dt2[is.na(dt)]
    }

    # Ensure POSIXct and normalize display to 24-hour:
    # 1) strftime to "%Y-%m-%d %H:%M:%S" (24h),
    # 2) parse back to POSIXct so the column stays datetime (not character).
    data$date_time_hst <- as.POSIXct(
      strftime(dt, format = "%Y-%m-%d %H:%M:%S", tz = tz_hst),
      tz = tz_hst
    )
  }

  # Save out
  assign(tolower(gsub("\\..*", "", basename(file_list[i]))), data, envir = .GlobalEnv)
}


```


#Trimming
The following section is trimming the data and removing the times the loggers were out of the water. 

This is where manual input is needed. Manually add the new data name, and the specific time the logger was in and out of the water. Refer to the video for help in this section. 

Format:
'replace this with the data name' <- 'replace this with the data name' %>% 
  filter(date_time_hst >= "year-month-day hour:minute:sec" & date_time_hst <= "year-month-day hour:minute:sec)
  
Example: 
data_oxygen_septjan2024_kanewai_21446085 <- 
  data_oxygen_septjan2024_kanewai_21446085 %>% 
  filter(date_time_hst >= "2023-09-18 14:45:00" & date_time_hst <= "2024-01-18 10:19:00")
```{r}
# Trimming

data_oxygen_septjan2024_kanewai_21446085 <- 
  data_oxygen_septjan2024_kanewai_21446085 %>% 
  filter(date_time_hst >= ymd_hms("2023-09-18 14:45:00", tz = "Pacific/Honolulu") & date_time_hst <= ymd_hms("2024-01-18 10:19:00", tz = "Pacific/Honolulu"))

data_oxygen_septjan2024_kalauhaihai_21515403 <- 
  data_oxygen_septjan2024_kalauhaihai_21515403 %>% 
  filter(date_time_hst >= ymd_hms("2023-09-18 13:45:00", tz = "Pacific/Honolulu") & date_time_hst <= ymd_hms("2024-01-18 09:42:00", tz = "Pacific/Honolulu"))

data_oxygen_octnov2022_kalauhaihai_21446085 <- 
  data_oxygen_octnov2022_kalauhaihai_21446085 %>% 
  filter(date_time_hst >= ymd_hms("2022-10-06 10:10:00", tz = "Pacific/Honolulu") & date_time_hst <= ymd_hms("2022-11-08 09:30:00", tz = "Pacific/Honolulu"))

data_oxygen_febmar2024_kanewai_21515403 <- 
  data_oxygen_febmar2024_kanewai_21515403 %>% 
  filter(date_time_hst >= ymd_hms("2024-02-01 10:26:00", tz = "Pacific/Honolulu") & date_time_hst <= ymd_hms("2024-03-12 10:25:00", tz = "Pacific/Honolulu"))

data_oxygen_aprmay2023_kalauhaihai_21446085 <-
  data_oxygen_aprmay2023_kalauhaihai_21446085 %>% 
  filter(date_time_hst >= ymd_hms("2023-04-28 15:10:00", tz = "Pacific/Honolulu") & date_time_hst <= ymd_hms("2023-05-06 13:40:00", tz = "Pacific/Honolulu"))

data_oxygen_febapr2023_kanewaispringrock_21515403 <-
  data_oxygen_febapr2023_kanewaispringrock_21515403 %>% 
  filter(date_time_hst >= ymd_hms("2023-02-09 10:13:00", tz = "Pacific/Honolulu") & date_time_hst <= ymd_hms("2023-04-05 10:15:00", tz = "Pacific/Honolulu"))

data_oxygen_aprjuly2023_kanewai_21515403 <-
  data_oxygen_aprjuly2023_kanewai_21515403 %>% 
  filter(date_time_hst >= ymd_hms("2023-04-28 15:10:00", tz = "Pacific/Honolulu") & date_time_hst <= ymd_hms("2023-07-05 16:40:00", tz = "Pacific/Honolulu"))

data_oxygen_febmar2024_kalauhaihai_21446085 <-
  data_oxygen_febmar2024_kalauhaihai_21446085 %>% 
  filter(date_time_hst >= ymd_hms("2024-02-01 09:31:00", tz = "Pacific/Honolulu") & date_time_hst <= ymd_hms("2024-03-12 10:00:00", tz = "Pacific/Honolulu"))

data_oxygen_marjune2024_kalauhaihaigarage_21515403 <-
  data_oxygen_marjune2024_kalauhaihaigarage_21515403 %>%
  filter(date_time_hst >= ymd_hms("2024-03-15 16:35:00", tz = "Pacific/Honolulu") & date_time_hst <= ymd_hms("2024-06-13 13:04:00", tz = "Pacific/Honolulu"))

data_oxygen_marjune2024_kanewaispringrock_21446085 <-
  data_oxygen_marjune2024_kanewaispringrock_21446085 %>%
  filter(date_time_hst >= ymd_hms("2024-03-15 15:17:00", tz = "Pacific/Honolulu") & date_time_hst <= ymd_hms("2024-06-13 11:46:00", tz = "Pacific/Honolulu"))


data_oxygen_temp_marapr2025_kanewaispringrock_21515403 <-
  data_oxygen_temp_marapr2025_kanewaispringrock_21515403 %>%
  filter(date_time_hst >= ymd_hms("2025-03-07 15:50:00", tz = "Pacific/Honolulu") & date_time_hst <= ymd_hms("2025-04-03 10:27:00", tz = "Pacific/Honolulu"))


data_oxygen_temp_aprmay2025_kanewaispring_21515403 <-
  data_oxygen_temp_aprmay2025_kanewaispring_21515403 %>%
  filter(date_time_hst >= ymd_hms("2025-04-29 16:15:00", tz = "Pacific/Honolulu") & date_time_hst <= ymd_hms("2025-07-31 11:10:00", tz = "Pacific/Honolulu"))

data_oxygen_temp_aprjuly2025_kalauhaihaigarage_21446085 <-
  data_oxygen_temp_aprjuly2025_kalauhaihaigarage_21446085 %>%
  filter(date_time_hst >= ymd_hms("2025-04-29 15:00:00", tz = "Pacific/Honolulu") & date_time_hst <= ymd_hms("2025-07-31 9:40:00", tz = "Pacific/Honolulu"))

data_oxygen_temp_augoct2025_kanewaispring_21446085 <-
  data_oxygen_temp_augoct2025_kanewaispring_21446085 %>%
  filter(date_time_hst >= ymd_hms("2025-08-06 11:30:00", tz = "Pacific/Honolulu") & date_time_hst <= ymd_hms("2025-10-04 14:20:00", tz = "Pacific/Honolulu"))


```


#Join Data
This last section joins the data. One again manual input is needed. Add the new files separating by columns and new lines. 
```{r}
# join
oxygen_joined <- bind_rows(data_oxygen_septjan2024_kanewai_21446085,
  data_oxygen_septjan2024_kalauhaihai_21515403,
  data_oxygen_octnov2022_kalauhaihai_21446085,
  data_oxygen_febmar2024_kanewai_21515403,
  data_oxygen_aprmay2023_kalauhaihai_21446085,
  data_oxygen_febapr2023_kanewaispringrock_21515403,
  data_oxygen_aprmay2023_kalauhaihai_21446085,
  data_oxygen_febmar2024_kalauhaihai_21446085,
  data_oxygen_marjune2024_kalauhaihaigarage_21515403,
  data_oxygen_marjune2024_kanewaispringrock_21446085,
  data_oxygen_temp_marapr2025_kanewaispringrock_21515403,
  data_oxygen_temp_aprmay2025_kanewaispring_21515403,
  data_oxygen_temp_aprjuly2025_kalauhaihaigarage_21446085,
  data_oxygen_temp_augoct2025_kanewaispring_21446085) %>% 
  select(date_time_hst, oxygen, site)


```

#Write CSV
```{r}
write_csv(oxygen_joined, here("cleaned_data/oxygen_joined.csv"))
```

```{r}
a <- ggplot(oxygen_joined, aes(x = date_time_hst, 
                      y = oxygen, color = site)) +
  geom_line(size = 0.1) +
  theme_minimal()

ggplotly(a)
```
